---
title: "Data NoBlaBla TDS - Atelier R + Filtre Anti-Spam"
#author: "Géraud Dugé de Bernonville"
output:
  html_document:
    theme: spacelab
    toc: yes
    includes:
          before_body: include/ribbon.html
          after_body: include/license.html
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE, prompt=TRUE)
```

## Bases du langage

### Manipulation des vecteurs

Créer 3 vecteurs:

* prenoms: contenant les prénoms Alice, Bob, Carole
* ages: contenant les âges
* sexes: contenant _M_ ou _F_

```{r}
prenoms <- c('Alice', 'Bob', 'Carole')
sexe <- c('F', 'M', 'F')
ages <- c(24, 30, 23)
```

Afficher l'âge moyen (utiliser la fonction _mean_):
```{r}
mean(ages)
```

Calculer le nombre de femmes:
```{r}
sum(sexe == 'F')
```

### Data Frames

Les Data Frames permettent de stocker des tableaux de données, "à la Excel".
**cf. slides**

```{r}
prenoms <- c('Alice', 'Bob', 'Carole')
sexe <- c('F', 'M', 'F')
ages <- c(24, 30, 23)
monDataFrame <- data.frame(prenoms, sexe, ages)
monDataFrame

monDataFrame[2, 'prenoms']
monDataFrame$prenoms
```

Exo:

* Créer le data frame monDF avec les données ci-dessus
* Récupérer l'ensemble des couples (prenom, age)
* Calculer la moyenne d'âge
* Quelle personne est la plus âgée (on utilisera la fonction `which.max`)?

```{r}
monDataFrame[, c('prenoms', 'ages')]
mean(monDataFrame$ages)
monDataFrame[which.max(monDataFrame$ages),]
```

Table de contingence:
```{r}
table(monDataFrame$sexe)
```


Pour modifier le data.frame:
```{r}
monDataFrame$recu <- c(TRUE, FALSE, TRUE)
table(monDataFrame$sexe, monDataFrame$recu)
```

Aide-mémoire pour les indices des data.frames: [ROW, COL] -> ROW is COol

### Structures de contrôle (if, loop..)

Voir 
```{r}
?Control
```

## Cas d'utilisation spam filter

**cf. slide**

À partir d'un jeu de données contenant une liste de e-mails reconnus comme étant soit
spam soit ham, nous allons entraîné plusieurs modèles afin de pouvoir déterminer automatiquement
la nature d'un e-mail.

Dans le jeu de données, les e-mails sont représentés sous forme de vecteurs contenant les termes les plus présents et leurs occurences.

### Récupération et exploration des données

Récupérer les 2 jeux de données depuis les urls suivantes:

* [Données d'entraînement](https://raw.githubusercontent.com/geraudster/spamdata/master/emails_train.csv)
* [Données de test](https://raw.githubusercontent.com/geraudster/spamdata/master/emails_test.csv)

Chargement des données (par l'IHM) ou directement en R:
```{r}
trainSet <- read.csv('emails_train.csv')
testSet <- read.csv('emails_test.csv')

dim(trainSet)
colnames(trainSet)
str(trainSet)
summary(trainSet)
#View(spambase) # ou clic sur spambase dans l'onglet Environment
```

Exo:

* Afficher la répartition spam/ham pour chaque jeu de données (utiliser la fonction _table_)

```{r}
table(trainSet$spam)
table(testSet$spam)
```

Gestion du label de spam:
```{r}
trainSet$spam <- factor(trainSet$spam, levels = c(0,1), labels = c('ham', 'spam'))
str(trainSet$spam)
table(trainSet$spam)
```

On fait pareil pour le jeu de test:
```{r}
testSet$spam <- factor(testSet$spam, levels = c(0,1), labels = c('ham', 'spam'))
```

### Exploration

Nous allons utiliser les fonctionnalités de base pour le dessin de graphiques.

Quelques histogrammes:
```{r}
hist(trainSet$vinc)
hist(trainSet$like)
hist(trainSet$busi)
```


Une boxplot:
```{r}
boxplot(trainSet$vinc ~ trainSet$spam)
title('trainSet$vinc')
boxplot(trainSet$like ~ trainSet$spam, col = 'bisque')
boxplot(trainSet$meet ~ trainSet$spam)
boxplot(trainSet$pleas ~ trainSet$spam, col = c('bisque', 'blue'))
title('Colored boxplot')
boxplot(trainSet$thank ~ trainSet$spam)
```

On voit que certaines variables semblent avoir plus ou moins d'influence sur la caractérisation
de spam/ham. Nous allons voir comment déterminer automatiquement ces règles.

### Modélisation

* Bref rappel des principes de machine learning __cf. slides__

On utilise la fonction logit:

$\sigma(t) = \frac{1}{1 + e^{-t}}$

```{r}
library(ggplot2)
x <- seq(-6, 6, 0.01)
qplot(x, 1 / (1 + exp(-x)), geom = 'line')
```

* Problématique de la classification / présentation de la régression logistique

### Application de l'algo

```{r}
model.logit <- glm(spam ~ vinc + like + meet + pleas + thank, family = 'binomial', trainSet)
summary(model.logit)
```

L'unité est le logit, pour l'interprétation:

```{r}
exp(coef(model.logit))
round(exp(coef(model.logit)), 2)
```


Testons un modèle avec plus de variables:
```{r}
model.logit <- glm(spam ~ ., family = 'binomial', trainSet)
round(exp(coef(model.logit)), 2)
```

### Interprétation du modèle

```{r}
summary(model.logit)
exp(coef(model.logit))
```

### Évaluation du modèle (score, matrice de confusion) __slides__

```{r}
train.predictions <- predict(model.logit, newdata = trainSet, type = 'response')
train.confusionMat <- table(trainSet$spam, train.predictions >= 0.5)
train.confusionMat
(train.confusionMat[1,1] + train.confusionMat[2,2]) / nrow(trainSet)
sum(diag(train.confusionMat)) / nrow(trainSet)
```


Exo:

* Évaluer le modèle sur le jeu de test
* Calculer l'accuracy, la spécificité et la sensitivite

```{r}
test.predictions <- predict(model.logit, newdata = testSet, type = 'response')
test.confusionMat <- table(testSet$spam, test.predictions >= 0.5)
test.confusionMat
sum(diag(test.confusionMat)) / sum(test.confusionMat)
```

Définition d'une fonction pour calculer l'accuracy:
```{r}
accuracy <- function(confusionMatrix) {
  sum(diag(confusionMatrix)) / sum(confusionMatrix)
}

accuracy(test.confusionMat)
```


```{r}
# Spécificité
test.confusionMat[2,2] / sum(test.confusionMat[2,])

specificity <- function(confusionMatrix) {
  confusionMatrix[2,2] / sum(confusionMatrix[2,])
}
```

Définition de la fonction pour le calcul de la sensitivity
```{r}
# Sensitivity
test.confusionMat[1,1] / sum(test.confusionMat[1,])

sensitivity <- function(confusionMatrix) {
  confusionMatrix[1,1] / sum(confusionMatrix[1,])
}
```


### Modification du seuil

Exo:

* Évaluer le modèle avec différentes valeurs de seuil (par ex: 0.8, 0.2)

Avec une valeur de seuil plus pessimiste:
```{r}
train.confusionMat <- table(trainSet$spam, train.predictions >= 0.8)
train.confusionMat
accuracy(train.confusionMat)

test.confusionMat <- table(testSet$spam, test.predictions >= 0.8)
test.confusionMat
accuracy(test.confusionMat)
sensitivity(test.confusionMat)
specificity(test.confusionMat)
```

Avec une valeur de seuil plus optimiste:
```{r}
train.confusionMat <- table(trainSet$spam, train.predictions >= 0.2)
train.confusionMat
accuracy(train.confusionMat)

test.confusionMat <- table(testSet$spam, test.predictions >= 0.2)
test.confusionMat
accuracy(test.confusionMat)
sensitivity(test.confusionMat)
specificity(test.confusionMat)
```

### Création d'un arbre de décision

Installation des packages par RStudio ou directement en R:
```{r, cache=TRUE, warning=FALSE}
#install.packages('rpart')
#install.packages('rpart.plot')
```

```{r}
library(rpart)
library(rpart.plot)
```

Création du modèle:
```{r}
model.rpart <- rpart(spam ~ ., trainSet)
summary(model.rpart)
```

Exo:

* Entraîner le modèle sur les données du _trainSet_
* Evaluer le modèle sur les données du _trainSet_ puis du _testSet_

Interprétation:
```{r}
prp(model.rpart)
prp(model.rpart, extra = 1)
```

Prédiction sur les données du trainSet:
```{r}
train.predictions2 <- predict(model.rpart, newdata = trainSet)
train.confusionMat2 <- table(trainSet$spam, train.predictions2[,'spam'] >= 0.5)
train.confusionMat2
accuracy(train.confusionMat2)

test.predictions2 <- predict(model.rpart, newdata = testSet)
test.confusionMat2 <- table(testSet$spam, test.predictions2[,'spam'] >= 0.5)
test.confusionMat2
accuracy(test.confusionMat2)
specificity(test.confusionMat2)
sensitivity(test.confusionMat2)
```

Exo:

* Évaluer le modèle sur différentes valeurs de seuil (par ex: 0.8, 0.2)

Avec une valeur de seuil plus pessimiste:
```{r}
train.confusionMat2 <- table(trainSet$spam, train.predictions2[,'spam'] >= 0.8)
train.confusionMat2
accuracy(train.confusionMat2)

test.predictions2 <- predict(model.rpart, newdata = testSet)
test.confusionMat2 <- table(testSet$spam, test.predictions2[,'spam'] >= 0.8)
test.confusionMat2
accuracy(test.confusionMat2)
specificity(test.confusionMat2)
sensitivity(test.confusionMat2)
```

Avec une valeur de seuil plus optimiste:
```{r}
train.confusionMat2 <- table(trainSet$spam, train.predictions2[,'spam'] >= 0.2)
train.confusionMat2
accuracy(train.confusionMat2)

test.predictions2 <- predict(model.rpart, newdata = testSet)
test.confusionMat2 <- table(testSet$spam, test.predictions2[,'spam'] >= 0.2)
test.confusionMat2
accuracy(test.confusionMat2)
specificity(test.confusionMat2)
sensitivity(test.confusionMat2)
```


Validation du modèle:
```{r}
test.predictions2 <- predict(model.rpart, newdata = testSet)
test.confusionMat2 <- table(testSet$spam, test.predictions2[,'spam'] >= 0.5)
test.confusionMat2
accuracy(test.confusionMat2)
```

## Pour aller plus loin - les courbes de ROC

Dessinons la courbe ROC pour le modèle de régression logistique: 
```{r}
library(ggplot2)
library(ROCR)
predictions.logit <- prediction(test.predictions, testSet$spam)
perf.logit <- performance(predictions.logit, measure = 'tpr', x.measure = 'fpr')
roc.data <- data.frame(fpr=unlist(perf.logit@x.values),
                       tpr=unlist(perf.logit@y.values),
                       model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2) +
    geom_line(aes(y=tpr)) +
    ggtitle('Courbe ROC pour le modèle de régression logistique')
```

Maintenant pour le modèle de l'arbre de décision:

```{r}
predictions.rpart <- prediction(test.predictions2[,'spam'], testSet$spam)
perf.rpart <- performance(predictions.rpart, measure = 'tpr', x.measure = 'fpr')
roc.data <- data.frame(fpr=unlist(perf.rpart@x.values),
                       tpr=unlist(perf.rpart@y.values),
                       model="GLM")
ggplot(roc.data, aes(x=fpr, ymin=0, ymax=tpr)) +
    geom_ribbon(alpha=0.2) +
    geom_line(aes(y=tpr)) +
    ggtitle('Courbe ROC pour le modèle d\'arbre de décision')
```

## Bibliographie

* Intro à R: https://github.com/juba/intro-r
* http://www.cs.cmu.edu/~eugene/research/full/detect-scam.pdf
* http://cran.r-project.org/web/views/MachineLearning.html
* http://kooperberg.fhcrc.org/logic/documents/ingophd-logic.pdf
* Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. 
* Liste des modèles supportés par le package *caret*: http://topepo.github.io/caret/modelList.html

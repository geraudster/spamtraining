---
title: "Sujet Meetup TDS NoBlaBla"
author: "Géraud"
output:
  html_document:
    keep_md: yes
---

## Intro R

* R c'est quoi? les origines...
* Présentation RStudio

### R c'est quoi?

**R** est un dialecte de **S**.

S c'est quoi? C'est un environnement pour l'analyse statistique développé en Fortran 
par les laboratoires Bell dès 1976.
Il a été réécrit en C en 1988. 
En 1991, début de l'implémentation de R par l'université d'Aukland, pour pallier au fait que la version de S-PLUS
était propriétaire.

Jusqu'en 2008 S-PLUS devient la propriété de TIBCO.

2015: R en version 3.2

La philosophie de S / R: fournir un environnement interactif pour l'analyse statistique.

### RStudio

[Rstudio](http://www.rstudio.com/) est une société qui publie l'éditeur Rstudio (et d'autres services comme ShinyApps, Rpubs...)

Plusieurs versions sont disponibles dont une version *Open Source*.

## Les bases du langage

R est une grosse calculatrice qui fournit une interface REPL (Read-Eval-Print-Loop).

```{r}
1 + 2
log(5)
sqrt(25)
```

À tout moment, il est possible d'accéder à l'aide en ligne:

```{r}
?log
?sqrt
?`+`
```

### Opérateurs, valeurs, listes, dataframes

Utiliser des scalaires:
```{r}
1 + 2
log(5)
sqrt(25)
```

Affecter un résultat à une variable:
```{r}
result <- 1 + 2
result
```


Manipuler des vecteurs:

```{r}
c(1,2,3,4,5,6,7,8,9)
c(1:9)
c('a', 'b', 'c')
letters[1:3]
```

Les vecteurs ne contiennent que des données du même type:
```{r}
c(1,2,'toto')
```


Opérations entre scalaires et vecteurs:
```{r}
c(1:9) + 2
c(1:9) * 3
```

Opérations entre vecteurs:
```{r}
c(1:9)*c(1:9)
c(1:9)*c(2:4)
```

Les listes peuvent contenir des types différents:
```{r}
list(1,2,'toto')
maListe <- list(1,2,'toto')
maListe[2]
maListe[[2]]
```

Les Data Frames permettent de stocker des tableaux de données:
```{r}
prenoms <- c('Alice', 'Bob', 'Carole')
emails <- c('alice@example.com', 'bob@example.com', 'carole@example.com')
ages <- c(24, 30, 23)
monDataFrame <- data.frame(prenoms, emails, ages)
monDataFrame

monDataFrame[2, 'prenoms']
monDataFrame$prenoms
```

Aide-mémoire pour les indices des data.frames: [ROW, COL] -> ROW is COol


* Structure de contrôle (if, loop..)


## Cas d'utilisation spam filter

### Récupération et exploration des données

* Récupération du jeu de données (https://archive.ics.uci.edu/ml/datasets/Spambase)
* Un peu de stats descriptives, quelques plots
* *Réduction de dimensions ?*

Récupérer les données depuis l'url distante:
```{r, cache=TRUE}
url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.zip'
dest <- './data'
dir.create(dest)
download.file(url,
              paste(dest, 'spambase.zip', sep='/'), method = 'curl')
```

Ensuite on décompresse l'archive:
```{r, cache=TRUE}
unzip(paste(dest, 'spambase.zip', sep='/'), exdir=dest)
```

Regardons les fichiers créés:
```{r}
list.files(dest)
```

Chargement des données:
```{r}
spambase <- read.csv('data/spambase.data')

dim(spambase)
colnames(spambase)
head(spambase, 5)
#View(spambase) # ou clic sur spambase dans l'onglet Environment

table(spambase[,58])
```

Chargement des entêtes:
```{r}
spambase.names <- readLines('data/spambase.names')
spambase.names <- sub(':.*$', '', spambase.names[34:length(spambase.names)])
spambase.names [length(spambase.names) + 1] <- 'spam'

spambase.names
```

Renommage des colonnes du data.frame:
```{r}
colnames(spambase) <- spambase.names
spambase <- data.frame(spambase)
str(spambase)
class(spambase$spam)
```

Gestion du label de spam:
```{r}
spambase$spam <- factor(spambase$spam, c(0,1), labels = c('nospam', 'spam'))
str(spambase$spam)
table(spambase$spam)
```

### Exploration

Quelques histogrammes:
```{r}
hist(spambase$word_freq_people)
hist(spambase$`char_freq_(`)
```

Un histogramme plus avancé:
```{r}
hist(spambase$word_freq_order[spambase$spam == 'nospam'], col = 'blue', breaks = 20)
hist(spambase$word_freq_order[spambase$spam == 'spam'], col = 'red', add = T, breaks = 20)
```

On voit qu'il y a beaucoup de valeurs à 0 ou proche de 0 (**à voir si on normalise**).


### Modélisation

* Bref rappel des principes de machine learning

*dessin ?*

* Préparation train set / test set

```{r}
set.seed(123)
spambase.train.idx <- sample.int(nrow(spambase), nrow(spambase) * 0.8)
spambase.train <- spambase[spambase.train.idx,]
spambase.test <- spambase[-spambase.train.idx,]

dim(spambase.train)
dim(spambase.test)

prop.table(table(spambase.train$spam))
prop.table(table(spambase.test$spam))
```

* Problématique de la classification / présentation de la régression logistique
* Application de l'algo

```{r}
# model1 <- glm(spam ~ word_freq_free + word_freq_internet, data = spambase.train, family = "binomial")
# summary(model1)
model1 <- glm(spam ~ ., data = spambase.train, family = "binomial")
summary(model1)
```

* Interprétation du modèle

*TODO?*

* Évaluation du modèle (score, matrice de confusion)

```{r}
predictions1 <- predict(model1, newdata = spambase.test, type = "response")

# x <- seq(0,10,0.01)
# y <- predict(model1, newdata = x, type = "response")
# lines(spambase.test$word_freq_our, predictions1)

predictions1 <- sapply(predictions1, function (x) { if (x>0.5) 'spam' else 'nospam'})

table(spambase.test$spam, predictions1)
prop.table(table(spambase.test$spam, predictions1),1)
mean(predictions1 == spambase.test$spam)
```

### Utilisation de caret

```{r, echo=FALSE, cache=TRUE}
# install.packages(c('caret', 'e1071'))
library(caret)
```

```{r}
model2 <- train(spam ~ ., data = spambase.train, method = 'glm')
predictions2 <- predict(model2, newdata = spambase.test)
confusionMatrix(predictions2, spambase.test$spam)
```

Avec un arbre de décision:
```{r}
model3 <- train(spam ~ ., data = spambase.train, method = 'rpart')
predictions3 <- predict(model3, newdata = spambase.test)
confusionMatrix(predictions3, spambase.test$spam)

plot(model3$finalModel)
```

Une random forest:
```{r}
model4 <- train(spam ~ ., data = spambase.train, method = 'rf')
predictions4 <- predict(model4, newdata = spambase.test)
confusionMatrix(predictions4, spambase.test$spam)

```




Pour aller plus loin, introduction au package [caret](http://topepo.github.io/caret/index.html) et tests avec différents algorithmes de machine learning (arbres de décision, random forest, gbm, *Naive Bayes*...)

## Bibliographie

* http://www.cs.cmu.edu/~eugene/research/full/detect-scam.pdf
* http://cran.r-project.org/web/views/MachineLearning.html
* http://kooperberg.fhcrc.org/logic/documents/ingophd-logic.pdf
* Lichman, M. (2013). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. 
